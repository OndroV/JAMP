temp <- data.matrix(temp)
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = heat.colors(256), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
B <- "~/Desktop/Untitled 1.csv"
data <- read.csv(B, stringsAsFactors=F)
row.names(data) <- data[,1]
temp <- log10(temp)
temp[temp<0] <-0
temp <- data
temp <- log10(temp)
temp <- data[,-1]
temp <- log10(temp)
temp[temp<0] <-0
temp <- data.matrix(temp)
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,20))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,100))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,40))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,20))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,100))
data <- read.csv(A, stringsAsFactors=F)
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"
data <- read.csv(A, stringsAsFactors=F)
temp <- data[,-c(1,2, ncol(data))]
temp <- log10(temp)
temp[temp<0] <-0
temp <- data.matrix(temp)
temp <- data.matrix(data[,-c(1,2, ncol(data))])
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,100))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"
temp <- data[,-c(1,2, ncol(data))]
temp <- data[,-1]
temp <- log10(temp)
temp[temp<0] <-0
temp <- data.matrix(data[,-c(1,2, ncol(data))])
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
nba_heatmap
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)
temp <- data[,-c(1,2, ncol(data))]
temp
temp <- log10(temp)
temp
temp[temp<0] <-0
temp
temp <- data.matrix(temp)
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
B <- "~/Desktop/Untitled 1.csv"#
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
row.names(data) <- data[,2]#
temp <- data[,-c(1,2, ncol(data))]#
temp <- data[,-1]#
temp <- log10(temp)#
temp[temp<0] <-0#
temp <- data.matrix(temp)
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
B <- "~/Desktop/Untitled 1.csv"#
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
row.names(data) <- data[,2]#
temp <- data[,-c(1,2, ncol(data))]#
#temp <- data[,-1]#
temp <- log10(temp)#
temp[temp<0] <-0#
temp <- data.matrix(temp)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
?
? heatmap
# work in progres - not working jet#
OTU_plots <- function(file=table, out=""){#
B <- "~/Desktop/Untitled 1.csv"#
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
row.names(data) <- data[,2]#
temp <- data[,-c(1,2, ncol(data))]#
#temp <- data[,-1]#
temp <- log10(temp)#
temp[temp<0] <-0#
temp <- data.matrix(temp)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))#
subsample <- function(sequences, N){#
exp <- NULL#
#
#sampling of OTU table by sequences depth defined below#
for (i in 1:N){#
temp <- sample(data$BIN.URI, sequences, prob=data$Sequences, replace=T)#
exp[i] <- length(sort(table(temp)))#
}#
return(exp)#
}#
#
#number of subreads sampled cannot exceed the number of availble reads#
steps <- 10^c(seq(0,7, 0.1))#
steps[steps<sum(data$Sequences)]#
#
#table will contain number of sequences samples, mean bin count with st dev for all replicates#
tab <- data.frame("seqNumber"=1, "meanBIN"=1, "SDbin"=1)#
tab <- tab[-1,]#
#k is variable for sequences called by the function above#
for (k in steps[steps<sum(data$Sequences)]){#
#N=number of desierd replicates#
subset <- subsample(k, N=50)#
tab <- rbind(tab, cbind(k, mean(subset), sd(subset)))#
}#
#
write.csv(tab, file=paste(g,"_",sub("/Users/tbraukma/Desktop/mBRAVE_test/","",files[g]),sep=""))#
#
}
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"
data <- read.csv(A, stringsAsFactors=F)
row.names(data) <- data[,2]#
temp <- data[,-c(1,2, ncol(data))]#
#temp <- data[,-1]#
temp <- log10(temp)#
temp[temp<0] <-0#
temp <- data.matrix(temp)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))#
subsample <- function(sequences, N){#
exp <- NULL#
#
#sampling of OTU table by sequences depth defined below#
for (i in 1:N){#
temp <- sample(data$BIN.URI, sequences, prob=data$Sequences, replace=T)#
exp[i] <- length(sort(table(temp)))#
}#
return(exp)#
}#
#
#number of subreads sampled cannot exceed the number of availble reads#
steps <- 10^c(seq(0,7, 0.1))#
steps[steps<sum(data$Sequences)]#
#
#table will contain number of sequences samples, mean bin count with st dev for all replicates#
tab <- data.frame("seqNumber"=1, "meanBIN"=1, "SDbin"=1)#
tab <- tab[-1,]#
#k is variable for sequences called by the function above#
for (k in steps[steps<sum(data$Sequences)]){#
#N=number of desierd replicates#
subset <- subsample(k, N=50)#
tab <- rbind(tab, cbind(k, mean(subset), sd(subset)))#
}
data <- read.csv(A, Names, stringsAsFactors=F)
Names=NA
data <- read.csv(A, Names=NA, stringsAsFactors=F)
data <- read.csv(A, stringsAsFactors=F)
head(data)
data[1]
data[,1]
data <- read.csv(A, stringsAsFactors=F)
temp <- data[,-c(1,2, ncol(data))]
temp
data[,1]
data <- read.csv(A, stringsAsFactors=F)
data[,1]
data[1,]
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance
colSums(temp)
sums <- colSums(temp)
temp[1]
temp[1]/sums[1]
temp[k] <- temp[k]/sums[k]*100
temp[k]/sums[k]*100
temp[k]
temp
temp[k]
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]
# make relatuve abundance#
sums <- colSums(temp)
sums
temp[k]/sums[k]*100
k <- 1
temp[k]/sums[k]*100
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
}
temp
temp[nrow(temp):1]
temp[nrow(temp):1,]
temp <- temp[nrow(temp):1,]
temp <- log10(temp)
temp
is.finite(temp)
temp
is.finite(temp)]
is.finite(temp)
temp[is.finite(temp[1])] <-0
is.finite(temp[1]
)
is.finite(temp[1,])
?
? log10
is.finite(c(1,2,2,2))
temp[1,]
temp[is.finite(temp[,1])]
is.finite(temp[,1])
temp[,1][is.finite(temp[,1])]
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][!is.finite(temp[,k])] <-0	# remove inf#
}#
#
#invert#
temp <- temp[nrow(temp):1,]#
temp <- data.matrix(temp)
temp
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
log10(0.001)
log10(0.0001)
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][temp[,k]<-4] <- -4	# remove inf#
}#
#
#invert#
temp <- temp[nrow(temp):1,]#
temp <- data.matrix(temp)#
#
log10(0.0001)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
B <- "~/Desktop/Untitled 1.csv"#
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][!is.finite(temp[,k])] <- -4	# remove inf#
temp[,k][temp[,k]<-4] <- -4#
}#
#
#invert#
temp <- temp[nrow(temp):1,]#
temp <- data.matrix(temp)#
#
log10(0.01)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
temp
k <- 4
B <- "~/Desktop/Untitled 1.csv"#
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)
temp[k]/sums[k]*100
temp[k] <- log10(temp[k]) 			# log10
temp[k]
temp[,k][!is.finite(temp[,k])]
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][!is.finite(temp[,k])] <- NA	# remove inf#
#temp[,k][temp[,k]<-4] <- -4#
}
B <- "~/Desktop/Untitled 1.csv"#
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][!is.finite(temp[,k])] <- NA	# remove inf#
#temp[,k][temp[,k]<-4] <- -4#
}#
#
#invert#
temp <- temp[nrow(temp):1,]#
temp <- data.matrix(temp)#
#
log10(0.01)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap.2(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
library("gplots")
install.packages("gplots")
library("gplots")
heatmap.2(temp)
heatmap.2(temp, col=rev(heat.colors(256)))
temp
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][!is.finite(temp[,k])] <- NA	# remove inf#
temp[,k][temp[,k]<-4] <- -4#
}#
#
#invert#
temp <- temp[nrow(temp):1,]#
temp <- data.matrix(temp)#
#
log10(0.01)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
nba_heatmap <- heatmap.2(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
? heatmap.2
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)[-c(200: 256)]), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)[-c(100: 256)]), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(256)[-c(240: 256)]), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(1000)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(10000)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(heat.colors(1000)), scale="column", margins=c(5,10))
colorRampPalette("white", "blue", 100)
colorRampPalette("white", "blue")
colorRampPalette(c("white", "blue"), 100)
colorRampPalette(c("white", "blue"), 10)
colorRampPalette(c("white", "blue"))
mycol <- colorRampPalette(c("white", "blue"))
mycol(10)
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(mycol(10)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = rev(mycol(100)), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10), xlim=c(100, 0.01))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10), lim=c(100, 0.01))
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10), ylim=c(100, 0.01))
mycol <- colorRampPalette(c("white", "blue"))#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
heatmap.2(temp, col=mycol(100))
mycol
temp
B <- "~/Desktop/Untitled 1.csv"#
A <- "~/Desktop/Tutorial/H_U_cluster_otus/5_OTU_table_0.01_ZERO.csv"#
data <- read.csv(A, stringsAsFactors=F)#
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][!is.finite(temp[,k])] <- NA	# remove inf#
temp[,k][temp[,k]<4] <- -4#
}#
#
#invert#
temp <- temp[nrow(temp):1,]#
temp <- data.matrix(temp)#
#
log10(0.01)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
#
mycol <- colorRampPalette(c("white", "blue"))#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
temp
if(is.na(Names)){#
row.names(data) <- data[,2]#
} else {row.names(data) <- Names}#
#
temp <- data[,-c(1,2, ncol(data))]#
# make relatuve abundance#
sums <- colSums(temp)#
#
for (k in 1:ncol(temp)){#
temp[k] <- temp[k]/sums[k]*100#
temp[k] <- log10(temp[k]) 			# log10#
temp[,k][!is.finite(temp[,k])] <- NA	# remove inf#
temp[,k][temp[,k]< -4] <- -4#
}#
#
#invert#
temp <- temp[nrow(temp):1,]#
temp <- data.matrix(temp)#
#
log10(0.01)#
#temp <- data.matrix(data[,-c(1,2, ncol(data))])#
#
mycol <- colorRampPalette(c("white", "blue"))#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
mycol <- colorRampPalette(c("white", "blue3"))#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
mycol <- colorRampPalette(c("white", "blue5"))#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
mycol <- colorRampPalette(c("white", "blue3"))#
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
points(2,2)
points(0,0)
points(0,1)
points(0,0.5)
points(0.5,0.5)
points(20,0.5)
points(50,0.5)
points(30,0.5)
points(40,0.5)
points(50,0.5)
nba_heatmap <- heatmap(temp, Rowv=NA, Colv=NA, col = mycol(100), scale="column", margins=c(5,10))
library("JAMP") # v0.44
# U_cluster_otus v0.1#
#
Map2ref <- function(files="latest", refDB=NULL, id=0.97, strand="plus", onlykeephits=F, filter=0.01){#
folder <- Core(module="Map2ref")#
cat(file="log.txt", c("Version v0.1", "\n"), append=T, sep="\n")#
message(" ")#
#
if (files[1]=="latest"){#
source(paste(folder, "/robots.txt", sep=""))#
files <- list.files(paste(last_data, "/_data", sep=""), full.names=T)#
}#
# Dereplicate files using USEARCH#
dir.create(paste(folder, "/_data/1_derep", sep=""))#
#
new_names <- sub(".*(_data/.*)", "\\1", files)#
new_names <- sub("_PE.*", "_PE_derep.fasta", new_names)#
new_names <- sub("_data", "_data/1_derep", new_names)#
new_names <- paste(folder, "/", new_names, sep="")#
#
cmd <- paste("-fastx_uniques \"", files, "\" -fastaout \"", new_names, "\" -sizeout",  sep="")#
#
temp <- paste(length(files), " files are dereplicated (incl. singletons):", sep="")#
cat(file="log.txt", temp , append=T, sep="\n")#
message(temp)#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2("usearch", cmd[i], stdout=T, stderr=T)#
meep <- sub(".*_data/(.*)", "\\1", temp[i])#
cat(file="log.txt", meep, append=T, sep="\n")#
cat(file=paste(folder, "/_stats/1_derep_logs.txt", sep=""), meep, A, "\n", append=T, sep="\n")#
message(meep)#
}#
#
# add saving unused sequences as extra files!!!#
# Mapp to refDB#
dir.create(paste(folder, "/_data/2_mapping", sep=""))#
dir.create(paste(folder, "/_stats/map_logs", sep=""))#
dir.create(paste(folder, "/_data/3_nohit_fasta", sep=""))#
blast_names <- sub("1_derep", "2_mapping", new_names)#
blast_names <- sub("_derep.fasta", ".txt", blast_names)#
#
nohit <- sub("1_derep", "3_nohit_fasta", new_names)#
log_names <- sub("_data/2_mapping/", "_stats/map_logs/", blast_names)#
cmd <- paste("-usearch_global ", new_names, " -db \"", refDB, "\" -strand ", strand, " -id 0.97 -blast6out \"", blast_names, "\" -maxhits 1", " -notmatched \"", nohit, "\"", sep="")#
temp <- paste("Comparing ", length(cmd)," files with dereplicated reads (incl. singletons) against refDB: \"", sub(".*/(.*)", "\\1", refDB), "\" using \"usearch_global\" and Usearch.\n", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#
exp <- NULL#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2("usearch", cmd[i], stdout=T, stderr=T)#
cat(file= log_names[i], paste("usearch ", cmd[i], sep=""), "\n", A, append=F, sep="\n")#
#
meep <- sub("_data/.*/(.*)", "\\1", temp[i])#
pass <- sub(".*, (.*)% matched\r", "\\1", A[grep("matched\r", A)])#
exp <- rbind(exp, c(meep, pass))#
glumanda <- paste(meep," - ", pass, "% reads matched", sep="")#
cat(file="log.txt", glumanda, append=T, sep="\n")#
message(glumanda)#
}#
# condensing hit tables!#
files <- blast_names#
#
tab <- c("NULL")#
tab <- as.data.frame(tab, stringsAsFactors=F)#
names(tab) <- "ID"#
#
for (i in 1:length(files)){#
data <- read.csv(files[i], sep="\t", header=F, stringsAsFactors=F)#
#
names(data) <- c("query", "ref", "ident", "length", "mism", "gap", "qstart", "qend", "target_s", "target_e", "e.value", "bitscore")#
#
data <- data[,c(-11,-12)]#
#
data <- cbind(data, "abund"=as.numeric(sub(".*size=(.*);", "\\1", data$query)), stringsAsFactors=F)#
#
#head(data)#
#
temp <- aggregate(data$abund, by=list(data$ref), FUN="sum")#
tab <- merge(tab , temp, by.x="ID", by.y="Group.1", all=T, sort=T)#
names(tab)[i+1] <- sub(".*2_mapping/(.*).txt", "\\1", files[i])#
}#
#
tab <- tab[-1,] # remove NULL entry in the beginning#
tab[is.na(tab)] <- 0#
sequ <- read.fasta(refDB, forceDNAtolower=F, as.string=T)#
#
# KEEP ONLY HITS OR KEEP ALL IN DB#
if(onlykeephits){#
temp2 <- match(attr(sequ, "name"), tab$ID)#
tab2 <- cbind(tab, "sequ"=as.vector(unlist(sequ[temp2])))#
#
} else {#
temp2 <- data.frame("ID"=attr(sequ, "name"))#
#
tab2 <- merge(tab, temp2, "ID", all=T)#
tab2[is.na(tab2)] <- 0#
#
#add sequences#
temp2 <- match(attr(sequ, "name"), tab2$ID)#
tab2 <- cbind(tab2, "sequ"=as.vector(unlist(sequ[temp2])))#
#
}#
# filter to relative abundance#
rel_abund <- tab2#
#
sampleabundance <- colSums(rel_abund[,2:(ncol(rel_abund)-1)])#
for (i in 2:(ncol(rel_abund)-1)){#
rel_abund[i] <- rel_abund[i]/sampleabundance[i-1]*100#
rel_abund[i][rel_abund[i]<filter] <- 0#
}#
# write rel abundance tab#
rel_abund <- rel_abund[order(rowSums(rel_abund[-c(1, ncol(rel_abund))]), decreasing=T),] # sort table by row sums#
write.csv(file=paste(folder, "/3_rel_abundnace_ZEROs.csv", sep=""), rel_abund, row.names=F)#
# write RAW table#
tab2 <- tab2[order(rowSums(tab2[-c(1, ncol(tab2))]), decreasing=T),] # sort table by row sums#
#
write.csv(file=paste(folder, "/3_Raw_hit_table.csv", sep=""), tab2, row.names=F)#
# make plots!#
#
pdf(paste(folder, "/rel_zero2.pdf", sep=""), height=(nrow(rel_abund)+20)/10, width=(ncol(rel_abund)-1)/2)#
#
temp_heat <- rel_abund[,2:(ncol(rel_abund)-1)]#
row.names(temp_heat) <- rel_abund[,1]#
#
OTU_heatmap(temp_heat, abundance=F, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
dev.off()#
temp <- "\nModule completed!"#
message(temp)#
cat(file="log.txt", paste(Sys.time(), "*** Module completed!", "", sep="\n"), append=T, sep="\n")#
}
install_github("VascoElbrecht/JAMP", subdir="JAMP")
library("devtools")#
install_github("VascoElbrecht/JAMP", subdir="JAMP")
library("JAMP") # v0.44
# U_cluster_otus v0.1#
#
Map2ref <- function(files="latest", refDB=NULL, id=0.97, strand="plus", onlykeephits=F, filter=0.01){#
folder <- Core(module="Map2ref")#
cat(file="log.txt", c("Version v0.1", "\n"), append=T, sep="\n")#
message(" ")#
#
if (files[1]=="latest"){#
source(paste(folder, "/robots.txt", sep=""))#
files <- list.files(paste(last_data, "/_data", sep=""), full.names=T)#
}#
# Dereplicate files using USEARCH#
dir.create(paste(folder, "/_data/1_derep", sep=""))#
#
new_names <- sub(".*(_data/.*)", "\\1", files)#
new_names <- sub("_PE.*", "_PE_derep.fasta", new_names)#
new_names <- sub("_data", "_data/1_derep", new_names)#
new_names <- paste(folder, "/", new_names, sep="")#
#
cmd <- paste("-fastx_uniques \"", files, "\" -fastaout \"", new_names, "\" -sizeout",  sep="")#
#
temp <- paste(length(files), " files are dereplicated (incl. singletons):", sep="")#
cat(file="log.txt", temp , append=T, sep="\n")#
message(temp)#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2("usearch", cmd[i], stdout=T, stderr=T)#
meep <- sub(".*_data/(.*)", "\\1", temp[i])#
cat(file="log.txt", meep, append=T, sep="\n")#
cat(file=paste(folder, "/_stats/1_derep_logs.txt", sep=""), meep, A, "\n", append=T, sep="\n")#
message(meep)#
}#
#
# add saving unused sequences as extra files!!!#
# Mapp to refDB#
dir.create(paste(folder, "/_data/2_mapping", sep=""))#
dir.create(paste(folder, "/_stats/map_logs", sep=""))#
dir.create(paste(folder, "/_data/3_nohit_fasta", sep=""))#
blast_names <- sub("1_derep", "2_mapping", new_names)#
blast_names <- sub("_derep.fasta", ".txt", blast_names)#
#
nohit <- sub("1_derep", "3_nohit_fasta", new_names)#
log_names <- sub("_data/2_mapping/", "_stats/map_logs/", blast_names)#
cmd <- paste("-usearch_global ", new_names, " -db \"", refDB, "\" -strand ", strand, " -id 0.97 -blast6out \"", blast_names, "\" -maxhits 1", " -notmatched \"", nohit, "\"", sep="")#
temp <- paste("Comparing ", length(cmd)," files with dereplicated reads (incl. singletons) against refDB: \"", sub(".*/(.*)", "\\1", refDB), "\" using \"usearch_global\" and Usearch.\n", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#
exp <- NULL#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2("usearch", cmd[i], stdout=T, stderr=T)#
cat(file= log_names[i], paste("usearch ", cmd[i], sep=""), "\n", A, append=F, sep="\n")#
#
meep <- sub("_data/.*/(.*)", "\\1", temp[i])#
pass <- sub(".*, (.*)% matched\r", "\\1", A[grep("matched\r", A)])#
exp <- rbind(exp, c(meep, pass))#
glumanda <- paste(meep," - ", pass, "% reads matched", sep="")#
cat(file="log.txt", glumanda, append=T, sep="\n")#
message(glumanda)#
}#
# condensing hit tables!#
files <- blast_names#
#
tab <- c("NULL")#
tab <- as.data.frame(tab, stringsAsFactors=F)#
names(tab) <- "ID"#
#
for (i in 1:length(files)){#
data <- read.csv(files[i], sep="\t", header=F, stringsAsFactors=F)#
#
names(data) <- c("query", "ref", "ident", "length", "mism", "gap", "qstart", "qend", "target_s", "target_e", "e.value", "bitscore")#
#
data <- data[,c(-11,-12)]#
#
data <- cbind(data, "abund"=as.numeric(sub(".*size=(.*);", "\\1", data$query)), stringsAsFactors=F)#
#
#head(data)#
#
temp <- aggregate(data$abund, by=list(data$ref), FUN="sum")#
tab <- merge(tab , temp, by.x="ID", by.y="Group.1", all=T, sort=T)#
names(tab)[i+1] <- sub(".*2_mapping/(.*).txt", "\\1", files[i])#
}#
#
tab <- tab[-1,] # remove NULL entry in the beginning#
tab[is.na(tab)] <- 0#
sequ <- read.fasta(refDB, forceDNAtolower=F, as.string=T)#
#
# KEEP ONLY HITS OR KEEP ALL IN DB#
if(onlykeephits){#
temp2 <- match(attr(sequ, "name"), tab$ID)#
tab2 <- cbind(tab, "sequ"=as.vector(unlist(sequ[temp2])))#
#
} else {#
temp2 <- data.frame("ID"=attr(sequ, "name"))#
#
tab2 <- merge(tab, temp2, "ID", all=T)#
tab2[is.na(tab2)] <- 0#
#
#add sequences#
temp2 <- match(attr(sequ, "name"), tab2$ID)#
tab2 <- cbind(tab2, "sequ"=as.vector(unlist(sequ[temp2])))#
#
}#
# filter to relative abundance#
rel_abund <- tab2#
#
sampleabundance <- colSums(rel_abund[,2:(ncol(rel_abund)-1)])#
for (i in 2:(ncol(rel_abund)-1)){#
rel_abund[i] <- rel_abund[i]/sampleabundance[i-1]*100#
rel_abund[i][rel_abund[i]<filter] <- 0#
}#
# write rel abundance tab#
rel_abund <- rel_abund[order(rowSums(rel_abund[-c(1, ncol(rel_abund))]), decreasing=T),] # sort table by row sums#
write.csv(file=paste(folder, "/3_rel_abundnace_ZEROs.csv", sep=""), rel_abund, row.names=F)#
# write RAW table#
tab2 <- tab2[order(rowSums(tab2[-c(1, ncol(tab2))]), decreasing=T),] # sort table by row sums#
#
write.csv(file=paste(folder, "/3_Raw_hit_table.csv", sep=""), tab2, row.names=F)#
# make plots!#
#
pdf(paste(folder, "/rel_zero2.pdf", sep=""), height=(nrow(rel_abund)+20)/10, width=(ncol(rel_abund)-1)/2)#
#
temp_heat <- rel_abund[,2:(ncol(rel_abund)-1)]#
row.names(temp_heat) <- rel_abund[,1]#
#
OTU_heatmap(temp_heat, abundance=F, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
dev.off()#
temp <- "\nModule completed!"#
message(temp)#
cat(file="log.txt", paste(Sys.time(), "*** Module completed!", "", sep="\n"), append=T, sep="\n")#
}
Remove_last_folder()
gsub("I", "N", c("AAIAAA", "NAAINII"))
# U_cluster_otus v0.1#
#
U_cluster_otus <- function(files="latest", minuniquesize=2, strand="plus", filter=0.01, filterN=1, exe="usearch", exeV="vsearch", otu_radius_pct=3, mapp_singletons=T, maxaccepts=1, maxrejects=32,  delete_data=T, heatmap=T){#
#, unoise_min=NA - unoise denoising removed, no longer supported!#
#
folder <- Core(module="U_cluster_otus", delete_data=delete_data)#
cat(file="log.txt", c("Version v0.2", "\n"), append=T, sep="\n")#
message(" ")#
#
files_to_delete <- NULL#
#
A <- system2(exe, stdout=T)#
version <- as.numeric(sub("usearch v(.+)\\.+.*\\..*_.*", "\\1", A[1]))#
#
if(otu_radius_pct!=3){#
if(version > 8){#
temp <-  paste("WARNING: You did set a custom clustering treshold of ", otu_radius_pct, " but are using Usearch version ", version, "! The custom treshold was removed with version 9 (nothing I can do about this), thus please provide a path in exe to Usearch8, to make this work. You can download the older versionf rom the Usearch website. The script will stop now.", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
stop("Script stopped!")#
}#
}#
if (files[1]=="latest"){#
source(paste(folder, "/robots.txt", sep=""))#
files <- list.files(paste(last_data, "/_data", sep=""), full.names=T)#
}#
#
# check for empty files!#
empty <- !file.info(files)$size>0#
#
if(sum(empty)>0){#
temp <- paste("WARNING! ", sum(empty), " file", if(sum(empty>1)){"s do"} else {" does"}, " NOT contain sequences and are not included in clustering:", sep="", "\n", paste(files[empty], collapse="\n"), "\n")#
message(temp)#
cat(file="log.txt", temp , append=T, sep="\n")#
}#
excluded <- NULL#
excluded <- files[empty]#
#
# Dereplicate files using Vsearch#
if(mapp_singletons){#
dir.create(paste(folder, "/_data/1_derep_inc_singletons", sep=""))#
} else {#
dir.create(paste(folder, "/_data/1_derep_minsize_", minuniquesize, sep=""))#
}#
#
new_names <- sub(".*(_data/.*)", "\\1", files[!empty])#
new_names <- sub("_PE.*", "_PE_derep.fasta", new_names)#
if(mapp_singletons){#
new_names <- sub("_data", "_data/1_derep_inc_singletons", new_names)#
}else{#
new_names <- sub("_data", paste("_data/1_derep_minsize_", minuniquesize, sep=""), new_names)#
}#
new_names <- paste(folder, "/", new_names, sep="")#
cmd <- paste("-derep_fulllength \"", files[!empty], "\" -output \"", new_names, "\" -sizeout", if(! mapp_singletons){paste(" -minuniquesize ", minuniquesize, sep="")}, sep="")#
#
files_to_delete <- c(files_to_delete, new_names)#
#
if(mapp_singletons){#
temp <- paste(length(cmd), " files are dereplicated using Vsearch, but since mapp_singletons = T, sequences below minuniquesize =", minuniquesize, "are discarded in each sample;", sep="")#
} else {#
temp <- paste(length(cmd), " files are dereplicated (incl. singletons! Using Vsearch):", sep="")}#
cat(file="log.txt", temp , append=T, sep="\n")#
message(temp)#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2(exeV, cmd[i], stdout=T, stderr=T)#
meep <- sub(".*_data/(.*)", "\\1", temp[i])#
cat(file="log.txt", meep, append=T, sep="\n")#
cat(file=paste(folder, "/_stats/1_derep_logs.txt", sep=""), meep, A, "\n", append=T, sep="\n")#
message(meep)#
}#
# 2 make OTUs!#
# merge all files into one#
#
dir.create(paste(folder, "/_data/2_OTU_clustering", sep=""))#
#
cmd <- paste(paste(new_names, collapse=" "), " > ", folder, "/_data/2_OTU_clustering/A_all_files_united.fasta", collapse="", sep="")#
A <- system2("cat", cmd, stdout=T, stderr=T)#
#
files_to_delete <- c(files_to_delete, paste(folder, "/_data/2_OTU_clustering/A_all_files_united.fasta", sep=""))#
#
#check <- readLines("_data/2_OTU_clustering/A_all_files_united.fasta")#
#count <- as.numeric(sub(".*size=(.*)", "\\1", check))#
#sum(count, na.rm=T)#
#
# write logs#
#
temp <- paste(length(new_names), " dereplicated files where merged (inc singleotns) into file:\n\"",folder, "/_data/2_OTU_clustering/A_all_files_united.fasta\"", sep="")#
message("\n", temp)#
cat(file="log.txt", "\n", temp, append=T, sep="\n")#
cat(file=paste(folder, "/_stats/2_OTU_clustering_log.txt", sep=""), temp, "", paste("cat", cmd), append=T, sep="\n")#
#
# dereplicate "A_all_files_united.fasta" using Vsearch!#
cmd <- paste("-derep_fulllength ", folder, "/_data/2_OTU_clustering/A_all_files_united.fasta -output ", folder, "/_data/2_OTU_clustering/B_all_derep_min", minuniquesize, ".fasta -sizein -sizeout -minuniquesize ", minuniquesize, sep="")#
#
filename_all_unique <- paste("B_all_derep_min", minuniquesize, ".fasta", sep="")#
#
files_to_delete <- c(files_to_delete, paste(folder, "/_data/2_OTU_clustering/B_all_derep_min2.fasta", sep=""))#
A <- system2(exeV, cmd, stdout=T, stderr=T)#
#
temp <- paste("Total number of sequences (not dereplicated): ", sub(".*nt in (.*) seqs.*", "\\1", A[grep("seqs, min", A)]), "\n", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#
temp <- paste("United sequences are dereplicated with minuniquesize = ", minuniquesize , " into a total of ", sub("(.*) unique sequences.*", "\\1", A[grep(" unique sequences", A)]), " unique sequences.", "\n", "File prepared for OTU clustering: \"", filename_all_unique, "\"", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#
# derep log#
cat(file=paste(folder, "/_stats/2_OTU_clustering_log.txt", sep=""), "\n", paste("cat", cmd), "\n", A, "", append=T, sep="\n")#
#
# Actual clustering of dereplicated file #
OTU_file <- sub(".fasta", "_OTUs.fasta", filename_all_unique)#
OTU_file <- sub("B_", "C_", OTU_file)#
#
# add option to cluster OTUs at other tahn 3% (only wrks with usearch8 or lower)#
cmd <- paste(" -cluster_otus ", folder, "/_data/2_OTU_clustering/", filename_all_unique, " -otus ", folder, "/_data/2_OTU_clustering/", OTU_file, " -uparseout ", folder, "/_data/2_OTU_clustering/", sub(".fasta", "_OTUtab.txt", OTU_file), " -relabel OTU_ -strand ", strand, if(otu_radius_pct!=3){paste(" -otu_radius_pct ", otu_radius_pct, sep="")}, sep="")#
#
A <- system2(exe, cmd, stdout=T, stderr=T) # cluster OTUs!#
#
cat(file=paste(folder, "/_stats/2_OTU_clustering_log.txt", sep=""), "\n", paste("usearch", cmd), "\n", A, "", append=T, sep="\n")#
#files_to_delete <- c(files_to_delete, paste(folder, "/_data/2_OTU_clustering/", OTU_file, sep=""))#
files_to_delete <- c(files_to_delete, paste(folder, "/_data/2_OTU_clustering/", sub(".fasta", "_OTUtab.txt", OTU_file), sep=""))#
if(version!=8){#
chimeras <- sub(".*OTUs, (.*) chimeras\r", "\\1", A[grep("chimeras\r", A)])#
OTUs <- sub(".*100.0% (.*) OTUs, .* chimeras\r", "\\1", A[grep("chimeras\r", A)])#
} else {#
chimeras <- sub(".*OTUs, (.*) chimeras.*", "\\1", A[grep("chimeras.*", A)])#
OTUs <- sub(".*100.0% (.*) OTUs, .* chimeras.*", "\\1", A[grep("chimeras.*", A)])#
}#
#
temp <- paste("\n", "Clustering reads from \"", filename_all_unique, "\nminuniquesize = ", minuniquesize, "\nstrand = ", strand, "\nChimeras discarded: ", chimeras, "\nOTUs written: ", OTUs, " -> file \"", OTU_file, "\"\n", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
# compare against refernce sequences (including singletons)#
#
dir.create(paste(folder, "/_data/3_Compare_OTU_derep/", sep=""))#
dir.create(paste(folder, "/_stats/3_Compare_OTU_derep/", sep=""))#
#
blast_names <- sub("1_derep_inc_singletons", "3_Compare_OTU_derep", new_names)#
#
if(mapp_singletons){#
blast_names <- sub("1_derep_inc_singletons", "3_Compare_OTU_derep", new_names)#
}else{#
blast_names <- sub(paste("1_derep_minsize_", minuniquesize, sep=""), "3_Compare_OTU_derep", new_names)#
}#
#
blast_names <- sub("1_derep_unoise3", "3_Compare_OTU_derep", blast_names)#
blast_names <- sub("_PE_derep.*.fasta", ".txt", blast_names)#
log_names <- sub("_data", "_stats", blast_names)#
cmd <- paste("-usearch_global ", new_names, " -db ", "\"", folder, "/_data/2_OTU_clustering/", OTU_file, "\"", " -strand plus -id ", (100-otu_radius_pct)/100, " -blast6out \"", blast_names, "\" -maxhits 1 -maxaccepts ", maxaccepts, " -maxrejects ", maxrejects, sep="")#
#
files_to_delete <- c(files_to_delete, blast_names)#
#
temp <- paste("Comparing ", length(cmd)," files with dereplicated reads (incl. singletons) against OTUs \"", folder, "/", OTU_file, "\" using \"usearch_global\" with id=", (100-otu_radius_pct)/100,".\n", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#
exp <- NULL#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2(exe, cmd[i], stdout=T, stderr=T)#
cat(file= log_names[i], paste("usearch ", cmd[i], sep=""), "\n", A, append=F, sep="\n")#
#
meep <- sub("_data/.*/(.*)", "\\1", temp[i])#
pass <- sub(".*, (.*)% matched\r", "\\1", A[grep("matched\r", A)])#
exp <- rbind(exp, c(meep, pass))#
glumanda <- paste(meep," - ", pass, "% reads matched", sep="")#
cat(file="log.txt", glumanda, append=T, sep="\n")#
message(glumanda)#
}#
# check for empty files#
empty <- !file.info(blast_names)$size>0#
#
if(sum(empty)>0){#
temp <- paste("\nWARNING! ", sum(empty), " file", if(sum(empty>1)){"s do"} else {" does"}, " not contain any sequences matching the OTU sequences!", sep="", "\n", paste(files[empty], collapse="\n"))#
message(temp)#
cat(file="log.txt", temp , append=T, sep="\n")#
}#
#
excluded2 <- c(excluded, blast_names[empty])#
# Write raw data OTU table! incl OTU sequences#
files <- blast_names[!empty]#
#
tab <- c("NULL")#
tab <- as.data.frame(tab, stringsAsFactors=F)#
names(tab) <- "ID"#
#
for (i in 1:length(files)){#
data <- read.csv(files[i], sep="\t", header=F, stringsAsFactors=F)#
#
names(data) <- c("query", "otu", "ident", "length", "mism", "gap", "qstart", "qend", "target_s", "target_e", "e.value", "bitscore")#
#
data <- data[,c(-11,-12)]#
#
data <- cbind(data, "abund"=as.numeric(sub(".*size=(.*)", "\\1", data$query)), "otu_no"=sub("(.*)size.*", "\\1", data$otu), stringsAsFactors=F)#
#
head(data)#
#
temp <- aggregate(data$abund, by=list(data$otu_no), FUN="sum")#
tab <- merge(tab , temp, by.x="ID", by.y="Group.1", all=T, sort=T)#
names(tab)[i+1] <- sub(".*derep/(.*).txt", "\\1", files[i])#
}#
tab <- tab[-1,] # remove NULL entry in the beginning#
tab[is.na(tab)] <- 0#
#
mrew <- tab$ID#
mrew <- as.numeric(gsub("OTU_(.*)", "\\1", mrew))#
tab <- tab[order(as.numeric(mrew)),]#
if(length(excluded2)>0){#
# add excluded sequences#
excluded2 <- sub(".*/(.*)", "\\1", excluded2)#
excluded2 <- sub("(.*).txt", "\\1", excluded2)#
excluded2 <- sub("(.*)_PE_.*", "\\1", excluded2)#
#
if(length(excluded2)>0){#
zero <- NULL#
for(j in 1:length(excluded2)){#
zero <- cbind(zero, rep(0, nrow(tab)))#
}#
}#
#
# add zero to table#
zero <- data.frame(zero, stringsAsFactors=F)#
names(zero) <- excluded2#
#
# order table by file names!#
tab2 <- data.frame(tab, zero, stringsAsFactors=F)#
tab <- tab2[,c(1, order(names(tab2)[-1])+1)]#
}#
# add sequences!#
sequ <- read.fasta(paste(folder, "/_data/2_OTU_clustering/", OTU_file, sep=""), forceDNAtolower=F, as.string=T)#
#
# check for different numbers#
temp <- sort(table(unlist(c(names(sequ), tab$ID))), decreasing=T)#
temp <- temp[temp==1]#
if(length(temp)>0){#
report <- paste("\n\nWARNING: The following OTU", if(length(temp)>1){"s"}, " did not get any sequences assigned in read mapping. This might happen if they are very low abundant and closely related OTUs are near by. Still maybe take a look.\nAffected sequences: ", paste(names(temp), collapse=" "), sep="")#
message(report)#
cat(file="log.txt", report, append=T, sep="\n")#
}#
tab2 <- data.frame("sort"=as.numeric(sub("OTU_", "", tab[,1])), tab, "sequ"=unlist(sequ[match(tab$ID, names(sequ))]), stringsAsFactors=F)#
write.csv(file=paste(folder, "/3_Raw_OTU_table.csv", sep=""), tab2, row.names=F)#
temp <- "\n\nOTU table generated (including OTU sequences): 3_Raw_OTU_table.csv"#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
if(length(excluded)>0){#
exp <- rbind(exp, cbind(cbind(excluded), "empty fasta file"))#
exp[,1] <- sub(".*/(.*)", "\\1", exp[,1])#
exp[,1] <- sub("(.*).txt", "\\1", exp[,1])#
exp[,1] <- sub("(.*)_PE_.*", "\\1", exp[,1])#
#
exp <- exp[order(exp[,1]),]#
}#
#
exp2 <- data.frame("ID"=exp[,1], "Abundance"=colSums(tab[-1]), "pct_pass"=exp[,2], row.names=1:length(exp[,1]))#
write.csv(exp2, file=paste(folder, "/_stats/3_pct_matched.csv", sep=""))#
#
#### end raw data table#
### make abundance filtering#
if(!is.na(filter)){#
#tab2 <- read.csv(file="3_Raw_OTU_table.csv", stringsAsFactors=F)#
#
start <- which(names(tab2)=="ID")+1#
stop <- which(names(tab2)=="sequ")-1#
#
temp <- tab2[, start:stop]#
meep <- paste("Discarding OTUs with below ", filter, "% abundance across at least ", filterN, " out of ", ncol(temp), " samples.", sep="")#
message(meep)#
cat(file="log.txt", meep, append=T, sep="\n")#
#
temp2 <- temp#
sampleabundance <- colSums(temp)#
for (i in 1:ncol(temp)){#
temp2[i] <- temp[i]/sampleabundance[i]*100#
}#
#
temp2[is.na(temp2)] <- 0#
#
# subset OTUs#
subset <- rowSums(temp2>=filter)#
subset2 <- subset >= filterN#
#
# reporting#
meep <- paste("Discarded OTUs: ", sum(!subset2)," out of ",  length(subset2), " discarded (", round(100-sum(subset2)/length(subset2)*100, 2), "%)", sep="")#
message(meep)#
cat(file="log.txt", meep, append=T, sep="\n")#
#
#write subsetted OTU table#
#
exp <- tab2[subset2,]#
exp <- rbind(exp, NA)#
exp[nrow(exp), start:stop] <- colSums(tab2[!subset2, start:stop])#
exp$ID[nrow(exp)] <- paste("below_", filter, sep="")#
exp$sort[nrow(exp)] <- exp$sort[nrow(exp)-1]+1#
# make folder #
dir.create(paste(folder, "/_data/5_subset/", sep=""))#
write.csv(exp, file=paste(folder, "/_data/5_subset/5_OTU_sub_", filter, "_not_rematched.csv", sep=""), row.names=F)#
#
OTU_sub_filename <- paste(folder, "/_data/5_subset/5_OTU_sub_", filter, ".fasta", sep="")#
write.fasta(as.list(exp$sequ[-nrow(exp)]), exp$ID[-nrow(exp)], file.out=OTU_sub_filename)#
#
# remapping of reads against subsetted OTUs!#
# compare against refernce sequences (including singletons)#
#
dir.create(paste(folder, "/_data/5_subset/usearch_global", sep=""))#
dir.create(paste(folder, "/_stats/5_subset/", sep=""))#
#
blast_names <- sub("_PE_derep.*.fasta", ".txt", new_names)#
#
if(mapp_singletons){#
blast_names <- sub("1_derep_inc_singletons", "5_subset/usearch_global", blast_names)#
}else{#
blast_names <- sub(paste("1_derep_minsize_", minuniquesize, sep=""), "5_subset/usearch_global", blast_names)#
}#
#
blast_names <- sub("1_derep_unoise3", "5_subset/usearch_global", blast_names)#
log_names <- sub("_data/", "_stats/", blast_names)#
log_names <- sub("/usearch_global", "", log_names)#
cmd <- paste("-usearch_global ", new_names, " -db ", OTU_sub_filename, " -strand plus -id ", (100-otu_radius_pct)/100, " -blast6out ", blast_names, " -maxhits 1 -maxaccepts ", maxaccepts, " -maxrejects ", maxrejects, sep="")#
#
files_to_delete <- c(files_to_delete, blast_names)#
#
temp <- paste("\n\nRemapping ", length(cmd)," files (incl. singletons) against subsetted OTUs \"", OTU_sub_filename, "\" using \"usearch_global\" using id=",(100-otu_radius_pct)/100,".\n", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#
exp <- NULL#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2(exe, cmd[i], stdout=T, stderr=T)#
cat(file= log_names[i], paste(exe, " ", cmd[i], sep=""), "\n", A, append=F, sep="\n")#
#
meep <- sub(".*singletons/(.*)", "\\1", temp[i])#
pass <- sub(".*, (.*)% matched\r", "\\1", A[grep("matched\r", A)])#
exp <- rbind(exp, c(meep, pass))#
glumanda <- paste(meep," - ", pass, "% reads matched", sep="")#
cat(file="log.txt", glumanda, append=T, sep="\n")#
message(glumanda)#
}#
#
#Remapping end#
#
# Writing subsetted & remapped OTU table!#
# Write raw data OTU table! incl OTU sequences#
empty <- !file.info(blast_names)$size>0#
#
if(sum(empty)>0){#
temp <- paste("\nWARNING! ", sum(empty), " file", if(sum(empty>1)){"s do"} else {" does"}, " not contain any sequences matching the OTU sequences!", sep="", "\n", paste(blast_names[empty], collapse="\n"))#
message(temp)#
cat(file="log.txt", temp , append=T, sep="\n")#
}#
#
excluded2 <- c(excluded, blast_names[empty])#
files <- blast_names[!empty]#
#
tab <- c("NULL")#
tab <- as.data.frame(tab, stringsAsFactors=F)#
names(tab) <- "ID"#
#
for (i in 1:length(files)){#
data <- read.csv(files[i], sep="\t", header=F, stringsAsFactors=F)#
#
names(data) <- c("query", "otu", "ident", "length", "mism", "gap", "qstart", "qend", "target_s", "target_e", "e.value", "bitscore")#
#
data <- data[,c(-11,-12)]#
#
data <- cbind(data, "abund"=as.numeric(sub(".*size=(.*)", "\\1", data$query)), "otu_no"=sub("(.*)size.*", "\\1", data$otu), stringsAsFactors=F)#
#
head(data)#
#
temp <- aggregate(data$abund, by=list(data$otu_no), FUN="sum")#
tab <- merge(tab , temp, by.x="ID", by.y="Group.1", all=T, sort=T)#
names(tab)[i+1] <- sub(".*usearch_global/(.*).txt", "\\1", files[i])#
}#
#
head(tab)#
#
tab <- tab[-1,] # remove NULL entry in the beginning#
tab[is.na(tab)] <- 0#
#
mrew <- tab$ID#
mrew <- as.numeric(gsub("OTU_(.*)", "\\1", mrew))#
tab <- tab[order(as.numeric(mrew)),]#
# add sequences!#
#
sequ <- read.fasta(OTU_sub_filename, forceDNAtolower=F, as.string=T)#
#
tab2 <- data.frame("sort"=as.numeric(sub("OTU_", "", tab[,1])), tab, "sequ"=unlist(sequ), stringsAsFactors=F)#
#
names(tab2) <- sub(".*_data/5_subset/usearch_global/(.*).txt", "\\1", names(tab2)) # SUBSET HERE#
# add below treshold OTU counts!#
#
subSums <- read.csv(paste(folder, "/3_Raw_OTU_table.csv", sep=""))#
sums <- colSums(subSums[,-c(1,2, ncol(subSums))])#
subSums <- as.vector(c(subSums[nrow(subSums)-1, 1]+1, paste("below_", filter, sep=""), sums[sums>0]-colSums(tab2[-c(1,2, ncol(tab2))]), NA))#
tab3 <- rbind(tab2, subSums)#
# add samples with no hits!#
# add excluded samples#
if(length(excluded2)>0){#
excluded2 <- sub(".*/(.*)", "\\1", excluded2)#
excluded2 <- sub("(.*).txt", "\\1", excluded2)#
excluded2 <- sub("(.*)_PE_.*", "\\1", excluded2)#
#
if(length(excluded2)>0){#
zero <- NULL#
for(j in 1:length(excluded2)){#
zero <- cbind(zero, rep(0, nrow(tab3)))#
}#
}#
#
# add zero to table#
zero <- data.frame(zero)#
names(zero) <- excluded2#
# order table by file names!#
tab4 <- cbind(tab3[,-ncol(tab3)], zero)#
tab4 <- tab4[,c(1, 2, order(names(tab4)[c(-1, -2)])+2)]#
tab4 <- data.frame(tab4, "sequ"=tab3[,ncol(tab3)])#
} else {tab4 <- tab3}#
#
#head(tab4)#
#
# recalculate sample abundance after sorting table#
sampleabundance2 <- NULL#
for (f in 3:(ncol(tab4)-1)){#
sampleabundance2[f-2] <- sum(as.numeric(tab4[,f]))#
}#
# set values 2 zero#
#
expZERO <- tab4#
#d <- 8#
for (d in 3:(ncol(expZERO)-1)){#
#
ZERO <- as.numeric(expZERO[,d])/sampleabundance2[d-2]*100>=filter#
discarded <- sum(as.numeric(expZERO[-nrow(expZERO),d][!ZERO[-nrow(expZERO)]]))#
expZERO[-nrow(expZERO),d][!ZERO[-nrow(expZERO)]] <- 0 # set zero#
#
expZERO[nrow(expZERO),d] <- as.numeric(expZERO[nrow(expZERO),d])+ discarded # add counts to discarded#
#
}#
#
expZERO[,-ncol(expZERO)][is.na(expZERO[,-ncol(expZERO)])] <- 0#
#relative abundance table#
expZEROrel <- expZERO#
#d <- 8#
for (d in 3:(ncol(expZERO)-1)){#
#
expZEROrel[,d] <- as.numeric(expZERO[,d])/sampleabundance2[d-2]*100#
}#
expZEROrel[,-ncol(expZEROrel)][is.na(expZEROrel[,-ncol(expZEROrel)])] <- 0#
write.csv(file=paste(folder, "/5_OTU_table_", filter,".csv", sep=""), tab4, row.names=F)#
write.csv(file=paste(folder, "/5_OTU_table_", filter,"_ZERO.csv", sep=""), expZERO, row.names=F)#
write.csv(file=paste(folder, "/5_OTU_table_", filter,"_ZERO_rel.csv", sep=""), expZEROrel, row.names=F)#
#
temp <- paste("\n\nSubsetted OTU table generated (", filter, "% abundance in at least ", filterN," sample): ", sub(paste(folder, "/_data/5_subset/", sep=""), "", OTU_sub_filename), sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#### end subsetted OTU table#
#
} # end subsetting#
# make plots#
#
RAW <- read.csv(paste(folder, "/3_Raw_OTU_table.csv", sep=""), stringsAsFactors=F)#
#
if(!is.na(filter)){ # only highlight when subsetting#
KEEP <- read.csv(paste(folder, "/5_OTU_table_", filter,".csv", sep=""), stringsAsFactors=F)#
#
higlight <- rev(!RAW$ID %in% KEEP$ID)#
#
if(heatmap){#
pdf(paste(folder, "/_stats/OTU_plot_3_RAW.pdf", sep=""), height=(nrow(RAW)+20)/10, width=(ncol(RAW)-1)/2)#
#
OTU_heatmap(paste(folder, "/3_Raw_OTU_table.csv", sep=""), abundance=T, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
pos <- ncol(RAW) - 2.5#
for (i in 1:length(higlight)){#
#
if(higlight[i]){#
rect(pos, i-0.5, pos+1, i+0.5, col="Lightgray", border=F)#
text(pos+0.1, i, rev(RAW$ID)[i], adj=0, cex=0.5)#
}#
#
}#
dev.off()#
}#
#
if(heatmap){#
OTU_heatmap(paste(folder, "/5_OTU_table_", filter,".csv", sep=""), out=paste(folder, "/_stats/OTU_plot_5_", filter, ".pdf", sep=""), abundance=T, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
OTU_heatmap(paste(folder, "/5_OTU_table_", filter,"_ZERO.csv", sep=""), out=paste(folder, "/_stats/OTU_plot_5_", filter, "_ZERO.pdf", sep=""), abundance=T, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
OTU_heatmap(file=paste(folder, "/5_OTU_table_", filter,"_ZERO_rel.csv", sep=""), out=paste(folder, "/_stats/OTU_plot_5_", filter, "_ZERO_rel.pdf", sep=""), abundance=T, rel=T, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
} else { # only plot unfiltered data if zero filtering is applied!#
OTU_heatmap(paste(folder, "/3_Raw_OTU_table.csv", sep=""), out=paste(folder, "/_stats/3_Raw_OTU_table.pdf", sep=""), abundance=T, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
}#
} else {message("Heatmap generation skipped!")}#
#
cat(file=paste(folder, "/robots.txt", sep=""), "\n# DELETE_START", files_to_delete, "# DELETE_END", append=T, sep="\n")#
#
temp <- "\nModule completed!"#
message(temp)#
cat(file="log.txt", paste(Sys.time(), "*** Module completed!", "", sep="\n"), append=T, sep="\n")#
}
threads=NA
is.na(threads)
# U_cluster_otus v0.1#
#
Map2ref <- function(files="latest", refDB=NULL, id=0.97, minuniquesize=1, strand="plus", onlykeephits=T, filter=0.01, maxaccepts=1, maxrejects=32, exe="usearch", threads=NA, heatmap=T, delete_data=T, JV=F){#
A <- system2(exe, stdout=T)#
version <- as.numeric(sub("usearch v(.+)\\.+.*\\..*_.*", "\\1", A[1]))#
folder <- Core(module="Map2ref", delete_data=delete_data)#
cat(file="log.txt", c("Version v0.1", "\n"), append=T, sep="\n")#
message(" ")#
#
files_to_delete <- NULL#
#
if (files[1]=="latest"){#
source(paste(folder, "/robots.txt", sep=""))#
files <- list.files(paste(last_data, "/_data", sep=""), full.names=T)#
}#
# check for empty files!#
empty <- !file.info(files)$size>0#
#
if(sum(empty)>0){#
temp <- paste("WARNING! ", sum(empty), " file", if(sum(empty>1)){"s do"} else {" does"}, " NOT contain sequences and are not included in clustering:", sep="", "\n", paste(files[empty], collapse="\n"), "\n")#
message(temp)#
cat(file="log.txt", temp , append=T, sep="\n")#
}#
excluded <- NULL#
excluded <- files[empty]#
# Dereplicate files using USEARCH#
dir.create(paste(folder, "/_data/1_derep", sep=""))#
#
new_names <- sub(".*(/.*)", "_data\\1", files[!empty])#
new_names <- sub("_PE.*", "_PE_derep.fasta", new_names)#
new_names <- sub("_data", "_data/1_derep", new_names)#
new_names <- paste(folder, "/", new_names, sep="")#
#
cmd <- paste(if(version<9){"-derep_fulllength"}else{"-fastx_uniques"}, " \"", files[!empty], "\" -fastaout \"", new_names, "\" -sizeout -sizein -minuniquesize ", minuniquesize,  sep="")#
#
files_to_delete <- c(files_to_delete, new_names)#
#
temp <- paste(length(cmd), " files are dereplicated (incl. singletons):", sep="")#
cat(file="log.txt", temp , append=T, sep="\n")#
message(temp)#
temp <- new_names#
sequ_in <- NULL#
for (i in 1:length(cmd)){#
A <- system2(exe, cmd[i], stdout=T, stderr=T)#
meep <- sub(".*_data/(.*)", "\\1", temp[i])#
cat(file="log.txt", meep, append=T, sep="\n")#
cat(file=paste(folder, "/_stats/1_derep_logs.txt", sep=""), meep, A, "\n", append=T, sep="\n")#
message(meep)#
#
sequ_in[i] <- as.numeric(sub(".* (.*) seqs.*", "\\1", A[grep("seqs", A)]))#
}#
#
temp <- sub(".*/(.*)", "\\1", files)#
expTab <- data.frame("ID"=sub("(.*)_PE.*", "\\1", temp), stringsAsFactors=F, "sequ_in"=0)#
expTab$sequ_in[!empty] <- sequ_in#
temp <- suppressWarnings(as.numeric(substr(expTab$ID,1,1)))#
temp <- which(!is.na(temp))#
#
for(i in temp){#
expTab$ID[i] <- paste("X", expTab$ID[i], sep="")#
}#
#
expTab <- expTab[order(expTab$ID),]#
#
# add saving unused sequences as extra files!!!#
# Mapp to refDB#
dir.create(paste(folder, "/_data/2_mapping", sep=""))#
dir.create(paste(folder, "/_stats/map_logs", sep=""))#
dir.create(paste(folder, "/_data/3_nohit_fasta", sep=""))#
blast_names <- sub("1_derep", "2_mapping", new_names)#
blast_names <- sub("_derep.fasta", ".txt", blast_names)#
#
nohit <- sub("1_derep", "3_nohit_fasta", new_names)#
log_names <- sub("_data/2_mapping/", "_stats/map_logs/", blast_names)#
#
if(!JV){#
cmd <- paste("-usearch_global ", new_names, " -db \"", refDB, "\" -strand ", strand, " -id ", id, " -blast6out \"", blast_names, "\" -maxhits 1", " -notmatched \"", nohit, "\" -maxaccepts ", maxaccepts, " -maxrejects ", maxrejects, if(!is.na(threads)){paste(" -threads ", threads, sep="")}, sep="")#
} else { #legacy version, remove at some point#
cmd <- paste("-usearch_global ", new_names, " -db \"", refDB, "\" -strand ", strand, " -id ", id, " -blast6out \"", blast_names, "\" -notmatched \"", nohit, "\" -maxaccepts ", maxaccepts, " -maxrejects ", maxrejects, if(!is.na(threads)){paste(" -threads ", threads, sep="")}, sep="")#
}#
files_to_delete <- c(files_to_delete, blast_names)#
#
temp <- paste("Comparing ", length(cmd)," files with dereplicated reads (incl. singletons) against refDB: \"", sub(".*/(.*)", "\\1", refDB), "\" using \"usearch_global\" and Usearch. Minimum identity (id) is ", id, ".\n", sep="")#
message(temp)#
cat(file="log.txt", temp, append=T, sep="\n")#
#
exp <- NULL#
temp <- new_names#
for (i in 1:length(cmd)){#
A <- system2(exe, cmd[i], stdout=T, stderr=T)#
cat(file= log_names[i], paste("usearch ", cmd[i], sep=""), "\n", A, append=F, sep="\n")#
#
meep <- sub("_data/.*/(.*)", "\\1", temp[i])#
pass <- sub(".*, (.*)% matched\r", "\\1", A[grep("matched\r", A)])#
exp <- rbind(exp, c(meep, pass))#
glumanda <- paste(meep," - ", pass, "% reads matched", sep="")#
cat(file="log.txt", glumanda, append=T, sep="\n")#
message(glumanda)#
}#
# checking for empty files#
#
# check for empty files#
empty <- !file.info(blast_names)$size>0#
#
if(sum(empty)>0){#
temp <- paste("\nWARNING! ", sum(empty), " file", if(sum(empty>1)){"s do"} else {" does"}, " not contain any reads matching the reference sequences!", sep="", "\n", paste(files[empty], collapse="\n"))#
message(temp)#
cat(file="log.txt", temp , append=T, sep="\n")#
}#
#
excluded2 <- c(excluded, blast_names[empty])#
# condensing hit tables!#
files <- blast_names[!empty]#
#
tab <- c("NULL")#
tab <- as.data.frame(tab, stringsAsFactors=F)#
names(tab) <- "ID"#
for (i in 1:length(files)){#
data <- read.csv(files[i], sep="\t", header=F, stringsAsFactors=F)#
#
names(data) <- c("query", "ref", "ident", "length", "mism", "gap", "qstart", "qend", "target_s", "target_e", "e.value", "bitscore")#
#
data <- data[,c(-11,-12)]#
#
if(JV){ # legacy version, OTU sorting by OTU number, not recommended any where else.#
#
data <- data.frame(data, "OTUnum"=as.numeric(sub("OTU", "", data$ref)), stringsAsFactors=F)#
temp <- data[order(data$OTUnum, decreasing=F),]#
temp2 <- temp[order(temp$ident, decreasing=T),]#
temp3 <- temp2[order(temp2$query),]#
#
#temp4[temp4$query=="M00517:488:000000000-BV32D:1:1101:19803:2074;size=9961;",]#
#
temp4 <- temp3[!duplicated(temp3$query),]#
#
data <- temp4#
#
}#
data <- cbind(data, "abund"=as.numeric(sub(".*size=(.*);", "\\1", data$query)), stringsAsFactors=F)#
#
#head(data)#
#
temp <- aggregate(data$abund, by=list(data$ref), FUN="sum")#
tab <- merge(tab , temp, by.x="ID", by.y="Group.1", all=T, sort=T)#
names(tab)[i+1] <- sub(".*2_mapping/(.*).txt", "\\1", files[i])#
}#
names(tab) <- sub("_PE$", "", names(tab))#
tab <- tab[!tab$ID=="NULL",] # remove NULL entry#
tab[is.na(tab)] <- 0#
#
# re add empty files#
#
if(length(excluded2)>0){#
# add excluded sequences#
excluded2 <- sub(".*/(.*)", "\\1", excluded2)#
excluded2 <- sub("(.*).txt", "\\1", excluded2)#
excluded2 <- sub("(.*)_PE_.*", "\\1", excluded2)#
#
if(length(excluded2)>0){#
zero <- NULL#
for(j in 1:length(excluded2)){#
zero <- cbind(zero, rep(0, nrow(tab)))#
}#
}#
#
# add zero to table#
zero <- data.frame(zero, stringsAsFactors=F)#
names(zero) <- excluded2#
#
# order table by file names!#
tab2 <- data.frame(tab, zero, stringsAsFactors=F)#
tab <- tab2[,c(1, order(names(tab2)[-1])+1)]#
}#
# end readd#
sequ <- read.fasta(refDB, forceDNAtolower=F, as.string=T)#
#
# KEEP ONLY HITS OR KEEP ALL IN DB#
if(onlykeephits){#
temp2 <- match(tab$ID, attr(sequ, "name"))#
tab2 <- cbind(tab, "sequ"=as.vector(unlist(sequ[temp2])))#
#
} else {#
temp2 <- data.frame("ID"=attr(sequ, "name"))#
#
tab2 <- merge(tab, temp2, "ID", all=T)#
tab2[is.na(tab2)] <- 0#
#
#add sequences#
temp2 <- match(attr(sequ, "name"), tab2$ID)#
tab2 <- cbind(tab2, "sequ"=as.vector(unlist(sequ[temp2])))#
#
}#
# filter to relative abundance#
rel_abund <- tab2#
#
sampleabundance <- colSums(rel_abund[,2:(ncol(rel_abund)-1)])#
for (i in 2:(ncol(rel_abund)-1)){#
rel_abund[i] <- rel_abund[i]/sampleabundance[i-1]*100#
rel_abund[i][rel_abund[i]<filter] <- 0#
}#
rel_abund[is.na(rel_abund)] <- 0 # empty cols#
# write rel abundance tab#
rel_abund <- rel_abund[order(rowSums(rel_abund[-c(1, ncol(rel_abund))]), decreasing=T),] # sort table by row sums#
write.csv(file=paste(folder, "/3_rel_abundnace_ZEROs.csv", sep=""), rel_abund, row.names=F)#
# write RAW table#
tab2 <- tab2[order(rowSums(tab2[-c(1, ncol(tab2))]), decreasing=T),] # sort table by row sums#
#
write.csv(file=paste(folder, "/3_Raw_hit_table.csv", sep=""), tab2, row.names=F)#
# write stats file#
temp <- colSums(tab2[-c(1, ncol(tab2))])#
expTab <- data.frame(expTab, "reads_mapped"=temp, stringsAsFactors=F)#
temp <- round(expTab$reads_mapped/expTab$sequ_in*100, 2)#
temp[is.na(temp)] <- 0#
expTab <- data.frame(expTab, "pct_pass"=temp, stringsAsFactors=F)#
#
row.names(expTab) <- 1:nrow(expTab)#
#
write.csv(expTab, file=paste(folder, "/_stats/", sub("(.)_.*", "\\1", folder), "_3_pct_matched.csv", sep=""))#
# make plots!#
# % matched#
#
Sequences_lost(expTab$sequ_in, expTab$reads_mapped, expTab$ID, out=paste(folder, "/_stats/", sub("(.)_.*", "\\1", folder), "_Reads_mapped.pdf", sep=""), main=paste(folder, ": Reads mapped (with ", id, ")", sep=""))#
Sequences_lost(expTab$sequ_in, expTab$reads_mapped, expTab$ID, out=paste(folder, "/_stats/", sub("(.)_.*", "\\1", folder), "_Reads_mapped_rel.pdf", sep=""), main=paste(folder, ": Reads mapped (with ", id, ")", sep=""), rel=T)#
# heatmap#
if(heatmap){#
pdf(paste(folder, "/_stats/", sub("(.)_.*", "\\1", folder), "_rel_zero2.pdf", sep=""), height=(nrow(rel_abund)+20)/10, width=(ncol(rel_abund)-1)/2)#
#
temp_heat <- rel_abund[,2:(ncol(rel_abund)-1)]#
row.names(temp_heat) <- rel_abund[,1]#
#
OTU_heatmap(temp_heat, abundance=F, col=rev(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba")))#
dev.off()#
}#
cat(file=paste(folder, "/robots.txt", sep=""), "\n# DELETE_START", files_to_delete, "# DELETE_END", append=T, sep="\n")#
#
temp <- "\nModule completed!"#
message(temp)#
cat(file="log.txt", paste(Sys.time(), "*** Module completed!", "", sep="\n"), append=T, sep="\n")#
}
# U_truncate v0.1#
#
U_truncate <- function(files="latest", left=0, right=0, trunclen=NA, fastq=T, rename=T, discardshort=F exe="usearch", delete_data=T){#
#
folder <- Core(module="U_truncate", delete_data=delete_data)#
cat(file="log.txt", c("\n","Version v0.2", "\n"), append=T, sep="\n")#
message(" ")#
#
files_to_delete <- NULL#
#
if (files[1]=="latest"){#
source(paste(folder, "/robots.txt", sep=""))#
files <- list.files(paste(last_data, "/_data", sep=""), full.names=T)#
}#
#
temp <- paste("Starting to truncate reads of ", length(files), " samples.", sep="")#
message(temp)#
message(" ")#
cat(file="log.txt", temp, append=T, sep="\n")#
# new file names#
#
new_names <- sub(".*(_data/.*)", "\\1", files)#
if(rename){ # rename files to indicate trimming#
new_names <- sub(".fast", "_trunc.fast", new_names)#
}#
new_names <- paste(folder, "/", new_names, sep="")#
# allow for vector truncation (in case of r1 or r2)#
#
cmd <- paste("-fastx_truncate \"", files,"\"", " -stripleft ", left, " -stripright ", right, if(!is.na(trunclen)){paste(" -trunclen ", trunclen, sep="")}, if(fastq){" -fastqout "} else {" -fastaout "}, "\"", new_names, "\"", if(discardshort){paste(" -padlen ", trunclen, sep="")}, sep="")#
#
files_to_delete <- c(files_to_delete, new_names)#
#
tab_exp <- NULL#
for (i in 1:length(cmd)){#
system2(exe, cmd[i], stdout=T, stderr=T)#
#
new_count <- Count_sequences(new_names[i], fastq= fastq)#
old_count <- Count_sequences(files[i], fastq= fastq)#
passed <- round(new_count/old_count*100, digits=2)#
#
A <- system2(exe, paste("-fastx_info \"", new_names[i], "\" -secs 5", sep=""), stdout=T, stderr=T)#
medianL <- as.numeric(sub(".*median (.*), hi.*", "\\1", A[grep("Lengths min ", A)]))#
#
cat(file=paste(folder, "/_stats/log_length.txt", sep=""), new_names[i], "\n", A,"\n\n", append=T, sep="\n")#
tab_exp <- rbind(tab_exp, c(sub(".*_data/(.*)", "\\1", new_names[i]), new_count, passed, medianL))#
#
meep <- paste(sub(".*_data/(.*)", "\\1", new_names[i]), ": ", passed, "% passed - medianL: ", medianL, sep="")#
message(meep)#
cat(file="log.txt", meep, append=T, sep="\n")#
}#
#
cat(file="log.txt", "\n", append=T, sep="\n")#
#
tab_exp <- data.frame(tab_exp)#
names(tab_exp) <- c("Sample", "Abundance", "pct_pass", "medianL")#
write.csv(tab_exp, paste(folder, "/_stats/", sub("(.)_.*", "\\1", folder), "_truncate_pass.csv", sep=""))#
message(" ")#
message("Module completed!")#
#
cat(file=paste(folder, "/robots.txt", sep=""), "\n# DELETE_START", files_to_delete, "# DELETE_END", append=T, sep="\n")#
#
cat(file="log.txt", paste(Sys.time(), "*** Module completed!", "", sep="\n"), append=T, sep="\n")#
}
# U_truncate v0.1#
#
U_truncate <- function(files="latest", left=0, right=0, trunclen=NA, fastq=T, rename=T, discardshort=F, exe="usearch", delete_data=T){#
#
folder <- Core(module="U_truncate", delete_data=delete_data)#
cat(file="log.txt", c("\n","Version v0.2", "\n"), append=T, sep="\n")#
message(" ")#
#
files_to_delete <- NULL#
#
if (files[1]=="latest"){#
source(paste(folder, "/robots.txt", sep=""))#
files <- list.files(paste(last_data, "/_data", sep=""), full.names=T)#
}#
#
temp <- paste("Starting to truncate reads of ", length(files), " samples.", sep="")#
message(temp)#
message(" ")#
cat(file="log.txt", temp, append=T, sep="\n")#
# new file names#
#
new_names <- sub(".*(_data/.*)", "\\1", files)#
if(rename){ # rename files to indicate trimming#
new_names <- sub(".fast", "_trunc.fast", new_names)#
}#
new_names <- paste(folder, "/", new_names, sep="")#
# allow for vector truncation (in case of r1 or r2)#
#
cmd <- paste("-fastx_truncate \"", files,"\"", " -stripleft ", left, " -stripright ", right, if(!is.na(trunclen)){paste(" -trunclen ", trunclen, sep="")}, if(fastq){" -fastqout "} else {" -fastaout "}, "\"", new_names, "\"", if(discardshort){paste(" -padlen ", trunclen, sep="")}, sep="")#
#
files_to_delete <- c(files_to_delete, new_names)#
#
tab_exp <- NULL#
for (i in 1:length(cmd)){#
system2(exe, cmd[i], stdout=T, stderr=T)#
#
new_count <- Count_sequences(new_names[i], fastq= fastq)#
old_count <- Count_sequences(files[i], fastq= fastq)#
passed <- round(new_count/old_count*100, digits=2)#
#
A <- system2(exe, paste("-fastx_info \"", new_names[i], "\" -secs 5", sep=""), stdout=T, stderr=T)#
medianL <- as.numeric(sub(".*median (.*), hi.*", "\\1", A[grep("Lengths min ", A)]))#
#
cat(file=paste(folder, "/_stats/log_length.txt", sep=""), new_names[i], "\n", A,"\n\n", append=T, sep="\n")#
tab_exp <- rbind(tab_exp, c(sub(".*_data/(.*)", "\\1", new_names[i]), new_count, passed, medianL))#
#
meep <- paste(sub(".*_data/(.*)", "\\1", new_names[i]), ": ", passed, "% passed - medianL: ", medianL, sep="")#
message(meep)#
cat(file="log.txt", meep, append=T, sep="\n")#
}#
#
cat(file="log.txt", "\n", append=T, sep="\n")#
#
tab_exp <- data.frame(tab_exp)#
names(tab_exp) <- c("Sample", "Abundance", "pct_pass", "medianL")#
write.csv(tab_exp, paste(folder, "/_stats/", sub("(.)_.*", "\\1", folder), "_truncate_pass.csv", sep=""))#
message(" ")#
message("Module completed!")#
#
cat(file=paste(folder, "/robots.txt", sep=""), "\n# DELETE_START", files_to_delete, "# DELETE_END", append=T, sep="\n")#
#
cat(file="log.txt", paste(Sys.time(), "*** Module completed!", "", sep="\n"), append=T, sep="\n")#
}
library("JAMP")
# U_truncate v0.1#
#
U_truncate <- function(files="latest", left=0, right=0, trunclen=NA, fastq=T, rename=T, discardshort=F, exe="usearch", delete_data=T){#
#
folder <- Core(module="U_truncate", delete_data=delete_data)#
cat(file="log.txt", c("\n","Version v0.2", "\n"), append=T, sep="\n")#
message(" ")#
#
files_to_delete <- NULL#
#
if (files[1]=="latest"){#
source(paste(folder, "/robots.txt", sep=""))#
files <- list.files(paste(last_data, "/_data", sep=""), full.names=T)#
}#
#
temp <- paste("Starting to truncate reads of ", length(files), " samples.", sep="")#
message(temp)#
message(" ")#
cat(file="log.txt", temp, append=T, sep="\n")#
# new file names#
#
new_names <- sub(".*(_data/.*)", "\\1", files)#
if(rename){ # rename files to indicate trimming#
new_names <- sub(".fast", "_trunc.fast", new_names)#
}#
new_names <- paste(folder, "/", new_names, sep="")#
# allow for vector truncation (in case of r1 or r2)#
#
cmd <- paste("-fastx_truncate \"", files,"\"", " -stripleft ", left, " -stripright ", right, if(!is.na(trunclen)){paste(" -trunclen ", trunclen, sep="")}, if(fastq){" -fastqout "} else {" -fastaout "}, "\"", new_names, "\"", if(discardshort){paste(" -padlen ", trunclen, sep="")}, sep="")#
#
files_to_delete <- c(files_to_delete, new_names)#
#
tab_exp <- NULL#
for (i in 1:length(cmd)){#
system2(exe, cmd[i], stdout=T, stderr=T)#
#
new_count <- Count_sequences(new_names[i], fastq= fastq)#
old_count <- Count_sequences(files[i], fastq= fastq)#
passed <- round(new_count/old_count*100, digits=2)#
#
A <- system2(exe, paste("-fastx_info \"", new_names[i], "\" -secs 5", sep=""), stdout=T, stderr=T)#
medianL <- as.numeric(sub(".*median (.*), hi.*", "\\1", A[grep("Lengths min ", A)]))#
#
cat(file=paste(folder, "/_stats/log_length.txt", sep=""), new_names[i], "\n", A,"\n\n", append=T, sep="\n")#
tab_exp <- rbind(tab_exp, c(sub(".*_data/(.*)", "\\1", new_names[i]), new_count, passed, medianL))#
#
meep <- paste(sub(".*_data/(.*)", "\\1", new_names[i]), ": ", passed, "% passed - medianL: ", medianL, sep="")#
message(meep)#
cat(file="log.txt", meep, append=T, sep="\n")#
}#
#
cat(file="log.txt", "\n", append=T, sep="\n")#
#
tab_exp <- data.frame(tab_exp)#
names(tab_exp) <- c("Sample", "Abundance", "pct_pass", "medianL")#
write.csv(tab_exp, paste(folder, "/_stats/", sub("(.)_.*", "\\1", folder), "_truncate_pass.csv", sep=""))#
message(" ")#
message("Module completed!")#
#
cat(file=paste(folder, "/robots.txt", sep=""), "\n# DELETE_START", files_to_delete, "# DELETE_END", append=T, sep="\n")#
#
cat(file="log.txt", paste(Sys.time(), "*** Module completed!", "", sep="\n"), append=T, sep="\n")#
}
barcodes <- read.csv(paste(system.file(package="JAMP"), "/BF_BR.csv", sep=""), stringsAsFactors=F)
barcodes
names(barcodes)
sum(names(barcodes)[1:3]!=c("barcode","rm","ID"))
names(barcodes)[1:3]!=c("barcode","rm","ID")
sum(names(barcodes)[1:3]==c("barcode","rm","ID"))
sum(names(barcodes)[1:3]==c("barcode","rm","ID"))!=3
message(paste(names(barcodes)))
names(barcodes)
message(paste(names(barcodes), collapse=""))
paste(names(barcodes), collapse="")
message(paste(names(barcodes), collapse="\t"))
message(paste(c("barcode","rm","ID"), collapse="\t"))
message("Tagging coulm names are not correct!")#
message(paste(names(barcodes), collapse="\t"))#
message("")#
message("Should be")#
message(paste(c("barcode","rm","ID"), collapse="\t"))#
stop()
if(sum(names(barcodes)[1:3]==c("barcode","rm","ID"))!=3){#
message("Tagging coulm names are not correct!")#
message(paste(names(barcodes), collapse="\t"))#
message("")#
message("Should be")#
message(paste(c("barcode","rm","ID"), collapse="\t"))#
stop("Function stopped!")#
}
message("Tagging coulm names are not correct!")#
message(paste(names(barcodes), collapse="\t"))#
message("")#
message("Should be")#
message(paste(c("barcode","rm","ID"), collapse="\t"))#
stop("Function stopped!")
install.packages(c("bold", "XML", "seqinr", "devtools", "fastqcr"), dependencies=T)#
# Load devtools and install package directly from GitHub#
library("devtools")#
install_github("VascoElbrecht/PrimerMiner", subdir="PrimerMiner")#
install_github("VascoElbrecht/JAMP", subdir="JAMP")
tags = "~/Documents/GitHub/JAMP/Tutorial/_converter/indexe_1.csv"
tags
barcodes <- read.csv(tags, stringsAsFactors=F)
barcodes
names(barcodes)[1:3]
names(barcodes)%in%c("barcode","rm","ID")
message("Tagging coulm names are not correct!")#
message(paste(names(barcodes), collapse="\t"))#
message("\n")#
message("Should be:")#
message(paste(c("barcode","rm","ID"), collapse="\t"))#
stop("Function stopped!")
names(combos)%in%"FileName"
combinations="~/Documents/GitHub/JAMP/Tutorial/_converter/combos_1.csv"
combos <- read.csv(combinations, stringsAsFactors=F)
combos
sum(names(combos)%in%"FileName")==1
nchar(barcodes$barcode)
message("A total of ", length(tagL), " barcodes detected in \"", tags, "\". " )
tagL <- nchar(barcodes$barcode)
message("A total of ", length(tagL), " barcodes detected in \"", tags, "\". " )
table(tagL)
length(table(tagL))==1
message("All tags have the length of ", tagL, ".")
message("All tags have the length of ", tagL[1], ".")
message("All tags have the length of ", tagL[1], ", looks good.")
paste(table(tagL))
tagL <- nchar(barcodes$barcode)
paste(table(tagL))
tagL
table(tagL)
tagL[3]<- 2
tagL
table(tagL)
paste(table(tagL))
table(tagL)
names(table(tagL))
message("Barcodes have difference length:", paste(names(table(tagL)), collapse=", ")
message("Barcodes have difference length:", paste(names(table(tagL)), collapse=", "))
message("Barcodes have difference length: ", paste(names(table(tagL)), collapse=", "))
stop("Please make sure barcodes have all the same length for demultiplexing!")
message("A total of ", length(tagL), " barcodes detected in \"", tags, "\". " )#
if(length(table(tagL))==1){#
message("All tags have the length of ", tagL[1], ", looks good.")#
tagL <- tagL[1]#
} else {#
message("Barcodes have difference length: ", paste(names(table(tagL)), collapse=", "))#
stop("Please make sure barcodes have all the same length for demultiplexing!")#
}
message("Barcodes have difference length: ", paste(names(table(tagL)), collapse=", "), " bp")
barcodes
